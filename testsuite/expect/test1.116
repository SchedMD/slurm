#!/usr/bin/env expect
############################################################################
# Purpose: Test of Slurm functionality
#          Extended MPI functionality tests via srun.
############################################################################
# Portions Copyright (C) 2019  SchedMD LLC.
# Copyright (C) 2002 The Regents of the University of California.
# Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).
# Written by Morris Jette <jette1@llnl.gov>
# CODE-OCEC-09-009. All rights reserved.
#
# This file is part of Slurm, a resource management program.
# For details, see <https://slurm.schedmd.com/>.
# Please also read the included file: DISCLAIMER.
#
# Slurm is free software; you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free
# Software Foundation; either version 2 of the License, or (at your option)
# any later version.
#
# Slurm is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more
# details.
#
# You should have received a copy of the GNU General Public License along
# with Slurm; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.
############################################################################
source ./globals

set file_in            "$test_dir/input"
set file_out           "$test_dir/output"
set file_err           "$test_dir/error"
set test_prog          "$test_name.prog"
set job_id             0

#
# Test for existence of mpi compiler
#
if {[info exists mpicc] == 0} {
	skip "mpicc not defined, can't perform mpi testing"
}
if {[file executable $mpicc] == 0} {
	skip "$mpicc does not exist"
}
if {[get_config_param "FrontendName"] ne "MISSING"} {
	skip "This test is incompatible with front-end systems"
}

proc cleanup {} {
	global job_id test_prog

	cancel_job $job_id
	file delete $test_prog ${test_prog}.o
}

#
# Compile the program
#
if {$use_pmi} {
	spawn $mpicc -Xlinker -rpath $slurm_dir/lib -L $slurm_dir/lib -lpmi -o $test_prog ${test_prog}.c
	expect {
		eof {
			wait
		}
	}
} else {
	spawn $mpicc -o $test_prog ${test_prog}.c
	expect {
		eof {
			wait
		}
	}
}
if {![file exists $test_prog]} {
	skip "Unable to build test program"
}

#
# Build input script file
#
make_bash_script $file_in "
  $bin_date
  $srun -n6 -t1 ./$test_prog
  $bin_date
  $bin_echo TEST_COMPLETE
"

#
# Spawn an sbatch job that uses stdout/err and confirm their contents
# NOTE: MPI_Bcast does not work with Multiple_Slurmd configurations
#
set timeout $max_job_delay
set no_start 0

if {[get_config_param "MULTIPLE_SLURMD"] eq "Yes"} {
	spawn $sbatch -N1 -n6 -O --output=$file_out --error=$file_err -t1 $file_in
} else {
	spawn $sbatch -N1-6 -n6 --output=$file_out --error=$file_err -t1 $file_in
}
expect {
	-re "Submitted batch job ($number)" {
		set job_id $expect_out(1,string)
		exp_continue
	}
	-re "Batch job submission failed" {
		set no_start 1
		exp_continue
	}
	-re "Unable to contact" {
		fail "Slurm appears to be down"
	}
	timeout {
		fail "srun not responding"
	}
	eof {
		wait
	}
}
if {$no_start != 0} {
	skip "Partition too small for test"
}
if {$job_id == 0} {
	fail "Batch submit failure"
}

#
# Wait for job to complete
#
wait_for_job -fail $job_id "DONE"

#
# Check for desired output in stdout
#
set expected_sum [expr 6 * 6]
wait_for_file -fail $file_out
set complete 0
set matches  0
set global_sum 0
spawn $bin_cat $file_out
expect {
	-re "Rank.($number). GlobalSum=($number)" {
		if {$expect_out(1,string) != 0} {
			fail "GlobalSum from wrong rank ($expect_out(1,string) != 0)"
		}
		incr global_sum $expect_out(2,string)
		incr matches
		exp_continue
	}
	-re "TEST_COMPLETE" {
		incr complete
		exp_continue
	}
	eof {
		wait
	}
}
set failure_message ""
if {$matches == 0} {
	set failure_message "No MPI communications occurred. The version of MPI you are using may be incompatible with the configured switch. Core files may be present from failed MPI tasks"
} elseif {$complete == 0} {
	set failure_message "Test failed to complete"
} elseif {$global_sum != $expected_sum} {
	set failure_message "Invalid global sum computed ($global_sum != $expected_sum)"
}

if {$failure_message ne ""} {
	set matches 0
	spawn head $file_err
	expect {
		-re "Error creating CQ" {
			incr matches
			exp_continue
		}
		eof {
			wait
		}
	}
	if {$matches != 0} {
		fail "$failure_message. If using MVAPICH then configure \"PropagateResourceLimitsExcept=MEMLOCK. Also start slurmd with \"ulimit -l unlimited\""
	} else {
		fail "$failure_message. Check contents of $file_err"
	}
}
