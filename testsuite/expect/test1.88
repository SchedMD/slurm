#!/usr/bin/env expect
############################################################################
# Purpose: Test of Slurm functionality
#          Basic test of MPI functionality via srun
############################################################################
# Copyright (C) 2002 The Regents of the University of California.
# Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).
# Written by Morris Jette <jette1@llnl.gov>
# CODE-OCEC-09-009. All rights reserved.
#
# This file is part of Slurm, a resource management program.
# For details, see <https://slurm.schedmd.com/>.
# Please also read the included file: DISCLAIMER.
#
# Slurm is free software; you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free
# Software Foundation; either version 2 of the License, or (at your option)
# any later version.
#
# Slurm is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more
# details.
#
# You should have received a copy of the GNU General Public License along
# with Slurm; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.
############################################################################
source ./globals

set file_in            "$test_dir/input"
set file_out           "$test_dir/output"
set file_err           "$test_dir/error"
set test_prog          "$test_name.prog"
set job_id             0

#
# Test for existence of mpi compiler
#
if {[info exists mpicc] == 0} {
	skip "Mpicc not defined, can't perform mpi testing"
}
if {[file executable $mpicc] == 0} {
	skip "$mpicc does not exist"
}
if {[get_config_param "FrontendName"] ne "MISSING"} {
	skip "This test is incompatible with front-end systems"
}

proc cleanup {} {
	global job_id test_prog

	cancel_job $job_id
	file delete $test_prog ${test_prog}.o
}

#
# Rebuild program
#
if {$use_pmi} {
	spawn $mpicc -Xlinker -rpath $slurm_dir/lib -L $slurm_dir/lib -lpmi -o $test_prog ${test_prog}.c
	expect {
		eof {
			wait
		}
	}
} else {
	spawn $mpicc -o $test_prog ${test_prog}.c
	expect {
		eof {
			wait
		}
	}
}
if {![file exists $test_prog]} {
	skip "Unable to build test program"
}

#
# OpenMPI can only run in multi-slurmd mode if no more than one node has
# more than one task. Individual nodes with more than one task use shared
# memory for communications and if more than one node is doing that, their
# shared memory use collides. That means these MPI tests will work if five
# nodes or more are available, otherwise some tests will fail. See test1.117
# for a variation of this test that will work with OpenMPI and multi-slurmd
# mode.
#
if {[get_config_param "MULTIPLE_SLURMD"] eq "Yes"} {
	log_warn "This test is limited with multiple slurmd systems"
	set tasks_over_nodes 1
} else {
	set tasks_over_nodes 2
}
#
# Build input script file
#
make_bash_script $file_in "
  $bin_date

  env | grep SLURM_JOB_NUM_NODES
  TASKS=\$((SLURM_JOB_NUM_NODES+$tasks_over_nodes))
  echo MPI_TASKS=\$TASKS

  $bin_echo test1_cyclic
  $srun -n \$TASKS --distribution=cyclic -t1 ./$test_prog

  $bin_date
  $bin_echo test2_block
  $srun -n \$TASKS --distribution=block -t1 ./$test_prog

  $bin_date
  $bin_echo test3_one_node
  $srun -n \$TASKS -N1 -O -t1 ./$test_prog

  $bin_date
  $bin_echo TEST_COMPLETE
"

#
# Spawn an sbatch job that uses stdout/err and confirm their contents
#
set timeout $max_job_delay
set no_start 0
spawn $sbatch -N1-6 -n8 --output=$file_out --error=$file_err -t2 $file_in
expect {
	-re "Submitted batch job ($number)" {
		set job_id $expect_out(1,string)
		exp_continue
	}
	-re "Batch job submission failed" {
		set no_start 1
		exp_continue
	}
	-re "Unable to contact" {
		fail "Slurm appears to be down"
	}
	timeout {
		fail "srun not responding"
	}
	eof {
		wait
	}
}

if {$no_start != 0} {
	skip "Partition too small for test"
}
if {$job_id == 0} {
	fail "Batch submit failure"
}

#
# Wait for job to complete
#
wait_for_job -fail $job_id "DONE"

#
# Check for desired output in stdout
#
wait_for_file -fail $file_out
set complete 0
set matches  0
set node_cnt 0
set task_cnt 0
set rank_sum 0
spawn $bin_cat $file_out
expect {
	-re "SLURM_JOB_NUM_NODES=($number)" {
		set node_cnt $expect_out(1,string)
		exp_continue
	}
	-re "MPI_TASKS=($number)" {
		set task_cnt $expect_out(1,string)
		exp_continue
	}
	-re "Rank.($number). on $re_word_str just received msg from Rank ($number)" {
		incr rank_sum $expect_out(1,string)
		incr rank_sum $expect_out(2,string)
		incr matches
		exp_continue
	}
	-re "TEST_COMPLETE" {
		incr complete
		exp_continue
	}
	eof {
		wait
	}
}
set expected_msg [expr $task_cnt * 3]
set expected_sum 0
for {set i 1} {$i < $task_cnt} {incr i} {
	incr expected_sum $i
}
set expected_sum [expr $expected_sum * 6]
set failure_message ""
if {$matches == 0} {
	set failure_message "No MPI communications occurred. The version of MPI you are using may be incompatible with the configured switch. Core files may be present from failed MPI tasks"
} elseif {$matches != $expected_msg} {
	set failure_message "Unexpected output ($matches of $expected_msg)"
} elseif {$complete == 0} {
	set failure_message "Test failed to complete"
} elseif {$rank_sum != $expected_sum} {
	set failure_message "Invalid rank values ($rank_sum != $expected_sum)"
}

if {$failure_message != ""} {
	set matches 0
	spawn head $file_err
	expect {
		-re "Error creating CQ" {
			incr matches
			exp_continue
		}
		eof {
			wait
		}
	}
	if {$matches != 0} {
		log_warn "If using MVAPICH then configure \"PropagateResourceLimitsExcept=MEMLOCK\". Also start slurmd with \"ulimit -l unlimited\""
	} else {
		log_debug "Check contents of $file_err"
	}

	fail $failure_message
}
