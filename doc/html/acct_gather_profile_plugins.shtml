<!--#include virtual="header.txt"-->
<!--  Copyright (C) 2013 Bull S. A. S.
      Bull, Rue Jean Jaures, B.P.68, 78340, Les Clayes-sous-Bois. -->

<h1><a name="top">Slurm Profile Accounting Plugin API (AcctGatherProfileType)
</a></h1>

<h2> Overview</h2>
<p> This document describes Slurm profile accounting plugins and the API that
defines them. It is intended as a resource to programmers wishing to write
their own Slurm profile accounting plugins.

<p>A profiling plugin allows more detailed information on the execution of jobs
than can reasonably be kept in the accounting database. (All jobs may also not
be profiled.)

A seperate
<a href="hdf5_profile_user_guide.html">User Guide</a> documents how to use
the hdf5 version of the plugin. An influxdb plugin is also available since
Slurm 17.11.

<p>The plugin provides an API for making calls to store data at various
points in a step's lifecycle. It collects data periodically from potentially
several sources. The periodic samples are eventually
consolidated into one <i>time series</i> dataset for each node of a job.

<p>The plugin's primary work is done within slurmstepd on the compute nodes.
It assumes a shared file system, presumably on the management network. This
avoids having to transfer files back to the controller at step end. Data is
typically gathered at job_acct_gather interval or acct_gather_energy interval
and the volume is not expected to be burdensome.

<p>The <i>hdf5</i> and <i>influxdb</i> implementations record I/O counts from
the network interface (Interconnect), I/O counts from the node from the Lustre
parallel file system, disk I/O counts, cpu and memory utilization
for each task, and a record of energy use.

<p>The <i>hdf5</i> implementation stores this data in a HDF5 file for each step
on each node for the jobs. A separate program
(<a href="sh5util.html">sh5util</a>) is provided to
consolidate all the node-step files in one container for the job.
HDF5 is a well known structured data set that allows different types of
related data to be stored in one file. Its internal structure resembles a
file system with <i>groups</i> being similar to <i>directories</i> and
<i>data sets</i> being similar to <i>files</i>. There are commodity programs,
notably <b>HDF5View</b> for viewing and manipulating these files.
<b>sh5util</b> also provides some capability for extracting subsets of date
for import into other analysis tools like spreadsheets.

<p>This plugin is incompatible with --enable-front-end. It you need to
simulate a large configuration, please use --enable-multiple-slurmd.
<p>Slurm profile accounting plugins must conform to the Slurm Plugin API with
the following specifications:
<p><span class="commandline">const char
plugin_name[]="<i>full&nbsp;text&nbsp;name</i>"</span>
<p style="margin-left:.2in">
A free-formatted ASCII text string that identifies the plugin.

<p><span class="commandline">const char
plugin_type[]="<i>major/minor</i>"</span><br>
<p style="margin-left:.2in">
The major type must be &quot;acct_gather_profile.&quot;
The minor type can be any suitable name
for the type of profile accounting. We currently use
<ul>
<li><b>none</b> &mdash; No profile data is gathered.
<li><b>hdf5</b> &mdash; Gets profile data about energy use, i/o sources
(Lustre, network) and task data such as local disk i/o,  CPU and memory usage.
</ul>

<p><span class="commandline">const uint32_t plugin_version</span><br>
If specified, identifies the version of Slurm used to build this plugin and
any attempt to load the plugin from a different version of Slurm will result
in an error.
If not specified, then the plugin may be loadeed by Slurm commands and
daemons from any version, however this may result in difficult to diagnose
failures due to changes in the arguments to plugin functions or changes
in other Slurm functions used by the plugin.</p>

<p>The programmer is urged to study
<span class="commandline">
src/plugins/acct_gather_profile/acct_gather_profile_hdf5.c</span> and
<span class="commandline">src/common/slurm_acct_gather_profile.c</span>
for a sample implementation of a Slurm profile accounting plugin.
<p class="footer"><a href="#top">top</a>

<h2>API Functions</h2>
<p>All of the following functions are required. Functions which are not
implemented must be stubbed.

<p class="commandline"> int init (void)
<p style="margin-left:.2in"><b>Description</b>:<br>
  Called when the plugin is loaded, before any other functions are
  called. Put global initialization here.
<p style="margin-left:.2in"><b>Returns</b>: <br>
  <span class="commandline">SLURM_SUCCESS</span> on success, or<br>
  <span class="commandline">SLURM_ERROR</span> on failure.</p>

<p class="commandline"> void fini (void)
<p style="margin-left:.2in"><b>Description</b>:<br>
  Called when the plugin is removed. Clear any allocated storage here.
<p style="margin-left:.2in"><b>Returns</b>: None.</p>

<p><b>Note</b>: These init and fini functions are not the same as those
described in the <span class="commandline">dlopen (3)</span> system library.
The C run-time system co-opts those symbols for its own initialization.
The system <span class="commandline">_init()</span> is called before the Slurm
<span class="commandline">init()</span>, and the Slurm
<span class="commandline">fini()</span> is called before the system's
<span class="commandline">_fini()</span>.</p>

<p class="commandline">
void acct_gather_profile_g_conf_options(void)
<p style="margin-left:.2in"><b>Description</b>:<br>
Called from slurmstepd between fork() and exec() of application.
Close open files<br>
<p style="margin-left:.2in"><b>Returns</b>: <br>
<span class="commandline">SLURM_SUCCESS</span> on success, or<br>
<span class="commandline">SLURM_ERROR</span> on failure.

<p class="commandline">
void acct_gather_profile_g_conf_options(s_p_options_t **full_options,
int *full_options_cnt)
<p style="margin-left:.2in"><b>Description</b>:<br>
Defines configuration options in acct_gather.conf<br>
<p style="margin-left:.2in"><b>Arguments</b>: <br>
<span class="commandline">full(out) option definitions.</span>
<span class="commandline">full_options_cnt(out) number in full.</span>
<p style="margin-left:.2in"><b>Returns</b>: <br>
<span class="commandline">SLURM_SUCCESS</span> on success, or<br>
<span class="commandline">SLURM_ERROR</span> on failure.

<p class="commandline">
void acct_gather_profile_g_conf_set(s_p_hashtbl_t *tbl)
<p style="margin-left:.2in"><b>Description</b>:<br>
Set configuration options from acct_gather.conf<br>
<p style="margin-left:.2in"><b>Arguments</b>: <br>
<span class="commandline">tbl -- hash table of options./span>
<p style="margin-left:.2in"><b>Returns</b>: <br>
<span class="commandline">SLURM_SUCCESS</span> on success, or<br>
<span class="commandline">SLURM_ERROR</span> on failure.

<p class="commandline">
void acct_gather_profile_g_conf_get(s_p_hashtbl_t *tbl)
<p style="margin-left:.2in"><b>Description</b>:<br>
Gets configuration options from acct_gather.conf<br>
<p style="margin-left:.2in"><b>Returns</b>: <br>
<span class="commandline">void* pointer to slurm_acct_gather_conf_t</span>
 on success, or<br> <span class="commandline">NULL</span> on failure.

<p class="commandline">
int acct_gather_profile_p_node_step_start(stepd_step_rec_t* job)
<p style="margin-left:.2in"><b>Description</b>:<br>
Called once per step on each node from slurmstepd, before launching tasks.
<br />
Provides an opportunity to create files and other node-step level
initialization.
<p style="margin-left:.2in"><b>Arguments</b>: <br>
<span class="commandline">job -- slumd_job_t structure containing information
about the step. </span>
<p style="margin-left:.2in"><b>Returns</b>: <br>
<span class="commandline">SLURM_SUCCESS</span> on success, or<br>
<span class="commandline">SLURM_ERROR</span> on failure.

<p class="commandline">
int acct_gather_profile_p_node_step_end(stepd_step_rec_t* job)
<p style="margin-left:.2in"><b>Description</b>:<br>
Called once per step on each node from slurmstepd, after all tasks end.
<br />
Provides an opportunity to close files, etc.
<p style="margin-left:.2in"><b>Arguments</b>: <br>
<span class="commandline">job -- slumd_job_t structure containing information
about the step. </span>
<p style="margin-left:.2in"><b>Returns</b>: <br>
<span class="commandline">SLURM_SUCCESS</span> on success, or<br>
<span class="commandline">SLURM_ERROR</span> on failure.

<p class="commandline">
int acct_gather_profile_p_task_start(stepd_step_rec_t* job, uint32_t taskid)
<p style="margin-left:.2in"><b>Description</b>:<br>
Called once per task from slurmstepd, BEFORE node step start is called.
<br />
Provides an opportunity to gather beginning values from node counters
(bytes_read ...)
<br />
<p style="margin-left:.2in"><b>Arguments</b>: <br>
<span class="commandline">job -- slumd_job_t structure containing information
about the step. </span>
<br /><span class="commandline">taskid -- Slurm taskid. </span>
<p style="margin-left:.2in"><b>Returns</b>: <br>
<span class="commandline">SLURM_SUCCESS</span> on success, or<br>
<span class="commandline">SLURM_ERROR</span> on failure.

<p class="commandline">
int acct_gather_profile_p_task_end(stepd_step_rec_t* job, pid_t taskpid)
<p style="margin-left:.2in"><b>Description</b>:<br>
Called once per task from slurmstepd.
<br />
Provides an opportunity to put final data for a task.
<p style="margin-left:.2in"><b>Arguments</b>: <br>
<span class="commandline">job -- slumd_job_t structure containing information
about the step. </span>
<br /><span class="commandline">pid -- task process id (pid_t). </span>
<p style="margin-left:.2in"><b>Returns</b>: <br>
<span class="commandline">SLURM_SUCCESS</span> on success, or<br>
<span class="commandline">SLURM_ERROR</span> on failure.

<p class="commandline">
int acct_gather_profile_p_add_sample_data(uint32_t type, void* data);
<p style="margin-left:.2in"><b>Description</b>:<br>
Put data at the Node Samples level. Typically called from something called
at either job_acct_gather interval or acct_gather_energy interval.
<br />
All samples in the same group will eventually be consolidated in one
time series.
<p style="margin-left:.2in"><b>Arguments</b>: <br>
<br /><span class="commandline">type -- identifies the type of data. </span>
<br /><span class="commandline">data -- data structure to be put to the file.
</span>
<p style="margin-left:.2in"><b>Returns</b>: <br>
<span class="commandline">SLURM_SUCCESS</span> on success, or<br>
<span class="commandline">SLURM_ERROR</span> on failure.

<h2>Parameters</h2>

<p>These parameters can be used in the slurm.conf to configure the
plugin and the frequency at which to gather node profile data.</p>
<dl>
<dt><span class="commandline">AcctGatherProfileType</span>
<dd>Specifies which plugin should be used.
</dl>

<p>The <a href="acct_gather.conf.html">acct_gather.conf</a> provides profile
configuration options.
<dl>
<dt><span class="commandline">ProfileDir</span>
<dd>Path to location in a shared file system in which to write profile data.
There is no default as there is no standard location for a shared file system.
It this parameter is not specified, no profiling will occur.
<dt><span class="commandline">ProfileDefaultProfile</span>
<dd>Default setting for --profile command line option for srun, salloc, sbatch.
</dl>
<p>The default profile value is <b>none</b> which means no profiling will be done
for jobs. The hdf5 plugin also includes;</p>
<ul>
<li>
<b>energy</b> sample energy use for the node.
</li>
<li>
<b>lustre</b> sample i/o to the Lustre file system for the node.
</li>
<li>
<b>network</b> sample i/o through the network (interconnect) interface
for the node.
</li>
<li>
<b>task</b> sample local disk I/O, cpu  and memory use for each task.
</li>
<li>
<b>all</b> all of the above.
</li>
</ul>
<p>Use caution when setting the default to values other than none as a file for
each job will be created. This option is provided for test systems.</p>

<p>Most of the sources of profile data are associated with various
acct_gather plugins. The acct_gather.conf file has setting for various
sampling mechanisms that can be used to change the frequency at which
samples occur.</p>

<h2>Data Types</h2>
<p>A plugin-like structure is implemented to generalize HDF5 data operations from
various sources. A <i>C</i> <b>typedef</b> is defined for each datatype. These
declarations are in /common/slurm_acct_gather_profile.h so the datatype are
common to all profile plugins.</p>

<p>The operations are defined via structures of function pointers, and they are
defined in /plugins/acct_gather_profile/common/profile_hdf5.h and should work
on any HDF5 implementation, not only hdf5.</p>

<p>Functions must be implemented to perform various operations for the datatype.
The api for the plugin includes an argument for the datatype so that the
implementation of that api can call the specific operation for that datatype.</p>

<p>Groups in the HDF5 file containing a dataset will include an attribute for
the datatype so that the program that merges step files into the job can
discover the type of the group and do the right thing.</p>

<p>For example, the typedef for the energy sample datatype;</p>
<pre>
typedef struct profile_energy {
    char     tod[TOD_LEN];	// Not used in node-step
    time_t   time;
    uint64_t watts;
    uint64_t cpu_freq;
} profile_energy_t;
</pre>
<p>
A <i>factory</i> method is implemented for each type to construct a structure
with functions implementing various operations for the type.
The following structure of functions is required for each type.
<pre>
/*
 * Structure of function pointers of common operations on a
 * profile data type. (Some may be stubs, particularly if the data type
 * does not represent a time series.
 *	dataset_size -- size of one dataset (structure size).
 *      create_memory_datatype -- creates hdf5 memory datatype
 *          corresponding to the datatype structure.
 *      create_file_datatype -- creates hdf5 file datatype
 *          corresponding to the datatype structure.
 *      create_s_memory_datatype -- creates hdf5 memory datatype
 *          corresponding to the summary datatype structure.
 *      create_s_file_datatype -- creates hdf5 file datatype
 *          corresponding to the summary datatype structure.
 *      init_job_series -- allocates a buffer for a complete time
 *          series (in job merge) and initializes each member
 *      merge_step_series -- merges all the individual time samples
 *          into a single data set with one item per sample.
 *          Data items can be scaled (e.g. subtracting beginning time)
 *          differenced (to show counts in interval) or other things
 *          appropriate for the series.
 *      series_total -- accumulate or average members in the entire
 *          series to be added to the file as totals for the node or
 *          task.
 *      extract_series -- format members of a structure for putting
 *          to a file data extracted from a time series to be imported into
 *          another analysis tool. (e.g. format as comma separated value.)
 *      extract_totals -- format members of a structure for putting
 *          to a file data extracted from a time series total to be imported
 *          into another analysis tool. (e.g. format as comma,separated value.)
 */
typedef struct profile_hdf5_ops {
    int   (*dataset_size) ();
    hid_t (*create_memory_datatype) ();
    hid_t (*create_file_datatype) ();
    hid_t (*create_s_memory_datatype) ();
    hid_t (*create_s_file_datatype) ();
    void* (*init_job_series) (int, int);
    void  (*merge_step_series) (hid_t, void*, void*, void*);
    void* (*series_total) (int, void*);
    void  (*extract_series) (FILE*, bool, int, int, char*,
				       char*, void*);
    void  (*extract_totals) (FILE*, bool, int, int, char*,
				       char*, void*);
} profile_hdf5_ops_t;
</pre>

<p>Note there are two different data types for supporting time series.<br>
1) A primary type is defined for gathering data in the node step file.
It is typically named profile_{series_name}_t.<br>
2) Another type is defined for summarizing series totals.
It is typically named profile_{series_name}_s_t. It does not have a 'factory'.
It is only used in the functions of the primary data type and the
primaries structure has operations to create appropriate hdf5 objects.</p>

<p>When adding a new type, the <b>profile_factory</b> function has to be
modified to return an <i>ops</i> for the type.</p>

<p>Interaction between type and hdf5.</p>
<ul>
<li>
The profile_{type}_t structure is used by callers of the <b>add_sample_data</b>
functions.
</li>
<li>
HDF5 needs a <b>memory</b>_datatype to transform this structure into its
dataset object in memory. The <i>create_memory_datatype</i> function creates
the appropriate object.
</li>
<li>
HDF5 needs a <b>file</b>_datatype to transform the dataset into how it will be
written to the HDF5 file (or to transform what it reads from a file into a
dataset.) The <i>create_file_datatype</i> function creates
the appropriate object.
</li>
</ul>

<p class="footer"><a href="#top">top</a>

<p style="text-align:center;">Last modified 27 March 2015</p>

<!--#include virtual="footer.txt"-->
