<!--#include virtual="header.txt"-->

<h1><a name="top">Slurm MPI Plugin API</a></h1>

<h2> Overview</h2>
<p> This document describes Slurm MPI selection plugins and the API that defines
them. It is intended as a resource to programmers wishing to write their own Slurm
node selection plugins.</p>

<p>Slurm MPI selection plugins are Slurm plugins that implement the which version of
mpi is used during execution of the new Slurm job. API described herein. They are
intended to provide a mechanism for both selecting MPI versions for pending jobs and
performing any mpi-specific tasks for job launch or termination. The plugins must
conform to the Slurm Plugin API with the following specifications:</p>
<p><span class="commandline">const char plugin_type[]</span><br>
The major type must be &quot;mpi.&quot; The minor type can be any recognizable
abbreviation for the type of node selection algorithm. We recommend, for example:</p>
<ul>
<li><b>pmi2</b> &mdash; For use with MPI2 and MVAPICH2.</li>
<li><b>pmix</b> &mdash; Exascale PMI implementation (currently supported by
	OpenMPI starting from version 2.0)</li>
<li><b>none</b> &mdash; For use with most other versions of MPI.</li>
</ul>
<p><span class="commandline">const char plugin_name[]</span><br>
Some descriptive name for the plugin.
There is no requirement with respect to its format.</p>
<p><span class="commandline">const uint32_t plugin_version</span><br>
If specified, identifies the version of Slurm used to build this plugin and
any attempt to load the plugin from a different version of Slurm will result
in an error.
If not specified, then the plugin may be loaded by Slurm commands and
daemons from any version, however this may result in difficult to diagnose
failures due to changes in the arguments to plugin functions or changes
in other Slurm functions used by the plugin.</p>

<p>A simplified flow of logic follows:
<ul>
<li>srun is able to specify the correct mpi to use with --mpi=MPITYPE</li>
<li>
	srun command runs
	<span class="commandline">p_mpi_hook_client_prelaunch()</span>
	which will set up the correct environment for the specified mpi.
</li>
<li>
	slurmstepd process runs
	<span class="commandline">p_mpi_hook_slurmstepd_prefork()</span>
	which will set configure the slurmd to use the correct mpi as well to interact with the srun.
</li>
<li>
	slurmstepd process runs
	<span class="commandline">p_mpi_hook_slurmstepd_task()</span>
	which executes immediately before fork/exec of each task.
</li>
<li>
	srun command runs
	<span class="commandline">p_mpi_hook_client_fini()</span>
	which executes after all tasks have finished.
</li>
</ul>


<h2>Data Objects</h2>
<p> These functions are expected to read and/or modify data structures directly in
the slurmd daemon's and srun memory. Slurmd is a multi-threaded program with independent
read and write locks on each data structure type. Therefore the type of operations
permitted on various data structures is identified for each function.</p>

<h2>Environment Variables</h2>
<p> Slurm will set the following environment variables for plugins:</p>
<ul>
<li><b>SLURM_MPI_TYPE</b> &mdash; MPI plugin name that has been loaded for job. </li>
</ul>

<h2>API Functions</h2>
<p>The following functions should be defined or at least be stubbed.</p>

<p class="commandline"> int init (void)
<p style="margin-left:.2in"><b>Description</b>:<br>
  Called when the plugin is loaded or reloaded, before any other functions are
  called. Put global initialization here.
<p style="margin-left:.2in"><b>Returns</b>: <br>
  <span class="commandline">SLURM_SUCCESS</span> on success, or<br>
  <span class="commandline">SLURM_ERROR</span> on failure.</p>

<p class="commandline"> void fini (void)
<p style="margin-left:.2in"><b>Description</b>:<br>
  Called when the plugin is removed or reloaded. Clear any allocated storage
  here.
<p style="margin-left:.2in"><b>Returns</b>: None.</p>

<p style="margin-left:.2in"><b>Note</b>: These init and fini functions are not the same as those
described in the <span class="commandline">dlopen (3)</span> system library.
The C run-time system co-opts those symbols for its own initialization.
The system <span class="commandline">_init()</span> is called before the Slurm
<span class="commandline">init()</span>, and the Slurm
<span class="commandline">fini()</span> is called before the system's
<span class="commandline">_fini()</span>.</p>

<p class="commandline">mpi_plugin_client_state_t*  p_mpi_hook_client_prelaunch  (const mpi_plugin_client_info_t *job, char ***env)</p>
<p style="margin-left:.2in"><b>Description</b>: Called by srun to configure the slurmd's environment
to that of the correct mpi.</p>
<p style="margin-left:.2in"><b>Arguments</b>:<br>
<span class="commandline">job</span>&nbsp;
&nbsp;&nbsp;(input) Pointer to the Job Step (stepd_step_rec_t) that about to run.
Cannot be NULL.<br>
<span class="commandline">env</span>&nbsp;
&nbsp;&nbsp;(input/output) Pointer to pointer of job environment to allow plugin
to modify job environment as needed.</p>
<p style="margin-left:.2in"><b>Returns</b>: SLURM_SUCCESS if successful. On
failure, the plugin should return SLURM_ERROR.</p>

<p class="commandline">int p_mpi_hook_slurmstepd_prefork(const stepd_step_rec_t *job, char ***env)</p>
<p style="margin-left:.2in"><b>Description</b>: Called by slurmstepd before
forking to create the first job process.  Most all the real processing happens
here. This is not called for batch jobs and extern steps.</p>
<p style="margin-left:.2in"><b>Arguments</b>:<br>
<span class="commandline">job</span>&nbsp;
&nbsp;&nbsp;(input) Pointer to the Job Step (stepd_step_rec_t) that about to run.
Cannot be NULL.<br>
<span class="commandline">env</span>&nbsp;
&nbsp;&nbsp;(input/output) Pointer to pointer of job environment to allow plugin
to modify job environment as needed.</p>
<p style="margin-left:.2in"><b>Returns</b>: SLURM_SUCCESS if successful. On
failure, the plugin should return SLURM_ERROR.</p>

<p class="commandline">void p_mpi_hook_slurmstepd_task(const mpi_plugin_task_info_t *job, char ***env)</p>
<p style="margin-left:.2in"><b>Description</b>:&nbsp;
Called by slurmstepd process immediately after fork and becoming job user, but
immediatly prior to exec of user task. This is not called for batch job steps
and extern steps.</p>
<p style="margin-left:.2in"><b>Arguments</b>:<br>
<span class="commandline">job</span>&nbsp;
&nbsp;&nbsp;(input) Pointer to the Job Step (stepd_step_rec_t) that about to run.
Cannot be NULL.<br>
<span class="commandline">env</span>&nbsp;
&nbsp;&nbsp;(input/output) Pointer to pointer of job environment to allow plugin
to modify job environment as needed.
</p><p style="margin-left:.2in"><b>Returns</b>: void returning function. </p>

<p class="commandline">int p_mpi_hook_client_fini(mpi_plugin_client_state_t *state);</p>
<p style="margin-left:.2in"><b>Description</b>: Called by srun after all tasks
are complete. Cleans up anything that needs cleaning up after execution.</p>
<p style="margin-left:.2in"><b>Arguments</b>:<br>
<span class="commandline">state</span>&nbsp;Launch state of MPI. Currently, a
typedef of void.
<p style="margin-left:.2in"><b>Returns</b>: SLURM_SUCCESS if successful. On
failure, the plugin should return SLURM_ERROR, causing slurmctld to exit.</p>

<p style="text-align:center;">Last modified 15 December 2018</p>

<!--#include virtual="footer.txt"-->
